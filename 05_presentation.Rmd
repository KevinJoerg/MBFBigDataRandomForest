---
title: "US Presidential election outcome explained by used car data"
author: "**Group Random Forest**: Kevin Joerg, Moritz DÃ¤ndliker, Tim Graf"
date: "Mai 20^th^ 2021"
output:  
  ioslides_presentation:
    widescreen: true

logo: ./Pictures_presentation/logo.png

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Agenda
1. Introduction
2. Data gathering & cleaning
3. Descriptive statistics
4. Linear Regressions (CPU&GPU)
5. XGBoost
6. Points of further consideration

## Introduction

The 2020 US-Presidential election led to highest voter turnout in history due to clash of socio-economic groups and ideologies:

<center>

### **Donald Trump Vs. Joe Bidden**

<font size="-0.3">

Conservative vs. Liberal

Urban vs. Rural

Climate Protectionists vs. Climate Change Deniers

Young vs. old

</font>
</center>

But are those socio-economic gaps also visible when it comes to the American's love for big cars?


## Research question
<center>

### Do car characteristics have any predictive power for the US-presidential voting outcome?

![*the big fight*](./Pictures_presentation/trump_truck.jpg)
<center>
## Data gathering(1/2)
### **Two data samples were used**

1. Used Car dataset ***(Kaggle)***
    
    <font size="-0.3">
    
    + 3 million cars xlisted on Cargurus as of Sept. 2020 in 1338/3006 counties
    + Each car reported with 66 characteristics
    + resulting in a total of ~200 million data points
    
    </font>
  **Total file size of ~9.3GB**

2. Two data sets for the voting outcome on a Precinct level and on a State level ***[MIT Election Lab]***

    <font size="-0.3">

    + Voting outcome in 30/50 states and 1427/3006 counties
    + Split of votes for Presidential candidates per jurisdiction
   
    </font>
  **Total size for both files ~0.2GB**

## Data merging and cleaning (2/2)

### **Merging:**


Problem : county level voting data vs. longitudonale/lattitudonale level car data


Solution: Package 'jvamisc' maps latitudinal & longitudinal car data to county

### **Cleaning approach**

1. Strain Splitting and variable type definition
2. Visually identified Outliers were excluded with an ff out-of-memory approach
    <style>
  .col2 {
    columns: 2 200px;         /* number of columns and width in pixels*/
    -webkit-columns: 2 200px; /* chrome, safari */
    -moz-columns: 2 200px;    /* firefox */
  }
  .col3 {
    columns: 3 100px;
    -webkit-columns: 3 100px;
    -moz-columns: 3 100px;
  }
  </style>
  <font size="-0.3">
  <div class="col2">
    - city fuel economy < 70 miles per gallon
    - highway fuel economy < 60 miles per gallon
    - Horsepower < 600
    - Price < 200'000 $
    
    - Mileage < 300'000 miles
    - rpm (revolutions per minute) < 2000
    - Savings Amount < 2500
    - year > 1900
  </div>
  </font>


## The sample in use (1/2)

### **Dependent variable:**
* democratic to republican voter outcome

<center>

$\frac{democraticvotes}{democratic votes + republican votes}$

</center>
### **Independant variables:**
<style>
  .col2 {
    columns: 2 200px;         /* number of columns and width in pixels*/
    -webkit-columns: 2 200px; /* chrome, safari */
    -moz-columns: 2 200px;    /* firefox */
  }
  .col3 {
    columns: 3 100px;
    -webkit-columns: 3 100px;
    -moz-columns: 3 100px;
  }
</style>
<font size="-0.5">
<div class="col2">
* Is new (if car is new or pre-owned)
* Price
* Fuel economy city (fuel consumption in the city)
* Mileage
* Horsepower

* Length
* Max seating
* Body type
* Brand name
* State
</div>
</font>
--> **Total sample size:** 2.6mio observations

## Sample in Use (2/2)

Available voting results by county

## Analysis Approaches

**Linear Regression on CPU**
    
    - regular

**Linear Regression on GPU**

    - package 'GPUtools' was used to ....
    - CUDA for INVIDIA GPUs (downfall: does not work on other GPUs)


**XGBoost**

    - Gradient boosted tree-concept deriving predictions from bootstrap aggregation
    - out-of-memory approach
    - Parallelization

## Linear regression Coefficients and Robustness
* Tested for heteroskedasticity and mulitcollinearity

## XGBoost parameter importance plot

Visualisation of Results with XGBoost

## Computational results

--> here a graph with adj. R2, RSME, and computational time to be shown

## Train Test

Show grwah here with R^2 etc. of train and test samples for both methodologies

## Results with XGBoost prediction

Show map with final prediction outcome by XGBoost estimator 

## Sources of Data

https://github.com/MEDSL/2020-elections-official
https://www.kaggle.com/ananaymital/us-used-cars-dataset

## Final resuts visualized

## XGBoost: Concept
<center>
![*coneptional framework by Tim Graf*](./Pictures_presentation/XGBoost.PNG){width=75%}
</center>

## Results with linear regression

Show map with final prediction outcome by linear estimator 

